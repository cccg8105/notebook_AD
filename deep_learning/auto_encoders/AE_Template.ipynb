{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AE_Template.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCPMWim8wSU7CWbUbd2Go4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cccg8105/notebook_AD/blob/deep_learning/deep_learning/auto_encoders/AE_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piIgX89iFe9l"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euXA6IRAFm9f"
      },
      "source": [
        "## Instalación de dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8so-sM--FcWD",
        "outputId": "3d02e8ba-0346-4c99-ee0e-65d9d6a46900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch===1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/53/914885a93a44b96c0dd1c36f36ff10afe341f091230aad68f7228d61db1e/torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8MB 21kB/s \n",
            "\u001b[?25hCollecting torchvision===0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/dc/4a939cfbd38398f4765f712576df21425241020bfccc200af76d19088533/torchvision-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 16.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch===1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch===1.6.0) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision===0.7.0) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.6.0 torchvision-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoLPybqPF23x"
      },
      "source": [
        "## Importar conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aHfdy6AF3qN"
      },
      "source": [
        "# Importar las librerías\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "movies = pd.read_csv(\"https://raw.githubusercontent.com/cccg8105/deeplearning-az/master/datasets/Part%205%20-%20Boltzmann%20Machines%20(BM)/ml-1m/movies.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users  = pd.read_csv(\"https://raw.githubusercontent.com/cccg8105/deeplearning-az/master/datasets/Part%205%20-%20Boltzmann%20Machines%20(BM)/ml-1m/users.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings  = pd.read_csv(\"https://raw.githubusercontent.com/cccg8105/deeplearning-az/master/datasets/Part%205%20-%20Boltzmann%20Machines%20(BM)/ml-1m/ratings.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "\n",
        "training_set = pd.read_csv(\"https://raw.githubusercontent.com/cccg8105/deeplearning-az/master/datasets/Part%205%20-%20Boltzmann%20Machines%20(BM)/ml-100k/u1.base\", sep = \"\\t\", header = None)\n",
        "# se convierte la estructura para el manejo en pytorch\n",
        "training_set = np.array(training_set, dtype = \"int\")\n",
        "test_set = pd.read_csv(\"https://raw.githubusercontent.com/cccg8105/deeplearning-az/master/datasets/Part%205%20-%20Boltzmann%20Machines%20(BM)/ml-100k/u1.test\", sep = \"\\t\", header = None)\n",
        "# se convierte la estructura para el manejo en pytorch\n",
        "test_set = np.array(test_set, dtype = \"int\")\n",
        "\n",
        "\n",
        "nb_users = int(max(max(training_set[:, 0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7VEB0WjGAoR"
      },
      "source": [
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_user in range(1, nb_users+1):\n",
        "        id_movies = data[:, 1][data[:, 0] == id_user]\n",
        "        id_ratings = data[:, 2][data[:, 0] == id_user]\n",
        "        ratings = np.zeros(nb_movies)\n",
        "        ratings[id_movies-1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6FsT-0JGpJf"
      },
      "source": [
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)\n",
        "\n",
        "# se convierten los datos a tipo de variable pytorch\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98e9MjLsGp98"
      },
      "source": [
        "## Crear la arquitectura de la Red Neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No5GvUpWGy7w"
      },
      "source": [
        "class SAE(nn.Module):\n",
        "    # constructor\n",
        "    def __init__(self, ):\n",
        "        nodosCapaOculta1 = 20\n",
        "        nodosCapaOculta2 = 10\n",
        "        nodosCapaOculta3 = 20\n",
        "\n",
        "        super(SAE, self).__init__()\n",
        "        # Creación de la primera capa con 20 nodos ocultos\n",
        "        self.fc1 = nn.Linear(nb_movies, nodosCapaOculta1)\n",
        "        # Creación de la segunda capa con 10 nodos ocultos\n",
        "        self.fc2 = nn.Linear(nodosCapaOculta1, nodosCapaOculta2)\n",
        "        # Creación de la tercera capa con 20 nodos ocultos\n",
        "        self.fc3 = nn.Linear(nodosCapaOculta2, nodosCapaOculta3)\n",
        "        # Creación de la capa final\n",
        "        self.fc4 = nn.Linear(nodosCapaOculta3, nb_movies)\n",
        "        # funcion de activacion\n",
        "        self.activation = nn.Sigmoid()\n",
        "    \n",
        "    #\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.activation(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXOwnHJKMSF7"
      },
      "source": [
        "sae = SAE()\n",
        "# funcion de perdidas\n",
        "criterion = nn.MSELoss()\n",
        "# optimizador\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi_iKQgzN89w"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvXXnW1lN_Eb"
      },
      "source": [
        "# cantidad de epocas\n",
        "nb_epoch = 200\n",
        "\n",
        "for epoch in range(1, nb_epoch+1):\n",
        "    train_loss = 0\n",
        "    s = 0.\n",
        "    for id_user in range(nb_users):\n",
        "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "        target = input.clone()\n",
        "        if torch.sum(target.data > 0) > 0:\n",
        "            output = sae.forward(input)\n",
        "            target.require_grad = False\n",
        "            output[target == 0] = 0\n",
        "            loss = criterion(output, target)\n",
        "            # la media no es sobre todas las películas, sino sobre las que realmente ha valorado\n",
        "            mean_corrector = nb_movies/float(torch.sum(target.data > 0)+1e-10) \n",
        "            loss.backward()\n",
        "            train_loss += np.sqrt(loss.data*mean_corrector) ## sum(errors) / n_pelis_valoradas\n",
        "            s += 1.\n",
        "            optimizer.step()\n",
        "    print(\"Epoch: \"+str(epoch)+\", Loss: \"+str(train_loss/s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPZuMzpEOX-q"
      },
      "source": [
        "## Evaluar conjunto test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuugCEU4ObYS"
      },
      "source": [
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "        output = sae.forward(input)\n",
        "        target.require_grad = False\n",
        "        output[target == 0] = 0\n",
        "        loss = criterion(output, target)\n",
        "        # la media no es sobre todas las películas, sino sobre las que realmente ha valorado\n",
        "        mean_corrector = nb_movies/float(torch.sum(target.data > 0)+1e-10) \n",
        "        test_loss += np.sqrt(loss.data*mean_corrector) ## sum(errors) / n_pelis_valoradas\n",
        "        s += 1.\n",
        "\n",
        "print(\"Test Loss: \"+str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}