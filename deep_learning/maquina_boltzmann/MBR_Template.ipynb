{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MBR_Template.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxqcDgzVI3a6qn5BJPkRw0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cccg8105/notebook_AD/blob/deep_learning/deep_learning/maquina_boltzmann/MBR_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3HGZvqELMdQ"
      },
      "source": [
        "# Máquina de Boltzmann restringida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIn6kX88LV2j"
      },
      "source": [
        "## Instalar dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHAdegkdLK1A",
        "outputId": "9121e8e2-2b97-46fd-b1f4-8aec08e8bbc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch===1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/53/914885a93a44b96c0dd1c36f36ff10afe341f091230aad68f7228d61db1e/torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8MB 14kB/s \n",
            "\u001b[?25hCollecting torchvision===0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/dc/4a939cfbd38398f4765f712576df21425241020bfccc200af76d19088533/torchvision-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch===1.6.0) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch===1.6.0) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision===0.7.0) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.6.0 torchvision-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzPgju40NpxY"
      },
      "source": [
        "## Importar conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXWqyHHGNy3A"
      },
      "source": [
        "# Importar las librerías\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "movies = pd.read_csv(\"https://raw.githubusercontent.com/cccg8105/deeplearning-az/master/datasets/Part%205%20-%20Boltzmann%20Machines%20(BM)/ml-1m/movies.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users  = pd.read_csv(\"https://raw.githubusercontent.com/cccg8105/deeplearning-az/master/datasets/Part%205%20-%20Boltzmann%20Machines%20(BM)/ml-1m/users.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings  = pd.read_csv(\"https://raw.githubusercontent.com/cccg8105/deeplearning-az/master/datasets/Part%205%20-%20Boltzmann%20Machines%20(BM)/ml-1m/ratings.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "\n",
        "training_set = pd.read_csv(\"https://raw.githubusercontent.com/cccg8105/deeplearning-az/master/datasets/Part%205%20-%20Boltzmann%20Machines%20(BM)/ml-100k/u1.base\", sep = \"\\t\", header = None)\n",
        "# se convierte la estructura para el manejo en pytorch\n",
        "training_set = np.array(training_set, dtype = \"int\")\n",
        "test_set = pd.read_csv(\"https://raw.githubusercontent.com/cccg8105/deeplearning-az/master/datasets/Part%205%20-%20Boltzmann%20Machines%20(BM)/ml-100k/u1.test\", sep = \"\\t\", header = None)\n",
        "# se convierte la estructura para el manejo en pytorch\n",
        "test_set = np.array(test_set, dtype = \"int\")\n",
        "\n",
        "\n",
        "nb_users = int(max(max(training_set[:, 0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSNYR1ojPTNS"
      },
      "source": [
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_user in range(1, nb_users+1):\n",
        "        # se obtienen peliculas valoradas por usuario\n",
        "        id_movies = data[:, 1][data[:, 0] == id_user]\n",
        "        # se obtienen valoraciones por usuario\n",
        "        id_ratings = data[:, 2][data[:, 0] == id_user]\n",
        "        # Se crea una matriz con los registros anteriores \n",
        "        ratings = np.zeros(nb_movies)\n",
        "        ratings[id_movies-1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pGoHRmTSgGW"
      },
      "source": [
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)\n",
        "\n",
        "# se convierten los datos a tipo de variable pytorch\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zbZYvePTXid"
      },
      "source": [
        "### Conversión de valoraciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRw9iiocTdgN"
      },
      "source": [
        "# Convertir las valoraciones a valores binarios 1 (Me gusta) o 0 (No me gusta)\n",
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >= 3] = 1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKFnqBpGTwqZ"
      },
      "source": [
        "## Contrucción de MBR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XwDzE0QT0Mj"
      },
      "source": [
        "class RBM():\n",
        "    def __init__(self, nv, nh):\n",
        "        self.W = torch.randn(nh, nv)\n",
        "        self.a = torch.randn(1, nh)\n",
        "        self.b = torch.randn(1, nv)\n",
        "    def sample_h(self, x):           #x = mini_batch_size x nv\n",
        "        wx = torch.mm(x, self.W.t()) #mini_batch_size x nh\n",
        "        activation = wx + self.a.expand_as(wx)\n",
        "        p_h_given_v = torch.sigmoid(activation)\n",
        "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "    def sample_v(self, y):           #y = mini_batch_size x nh\n",
        "        wy = torch.mm(y, self.W) #mini_batch_size x nv\n",
        "        activation = wy + self.b.expand_as(wy)\n",
        "        p_v_given_h = torch.sigmoid(activation)\n",
        "        return p_v_given_h, torch.bernoulli(p_v_given_h)   \n",
        "    def train(self, v0, vk, ph0, phk):\n",
        "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
        "        self.b += torch.sum((v0 - vk), 0)\n",
        "        self.a += torch.sum((ph0 - phk), 0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3Fan8sQUmp3"
      },
      "source": [
        "nv = len(training_set[0])\n",
        "nh = 100\n",
        "batch_size = 100\n",
        "\n",
        "rbm = RBM(nv, nh)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWMRs9vuUzYF"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCutaOthU2ng",
        "outputId": "8c1b1260-b428-476d-d01a-bf8e8142c9ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nb_epoch = 10\n",
        "for epoch in range(1, nb_epoch+1):\n",
        "    training_loss = 0\n",
        "    s = 0.\n",
        "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
        "        vk = training_set[id_user:id_user+batch_size]\n",
        "        v0 = training_set[id_user:id_user+batch_size]\n",
        "        ph0,_ = rbm.sample_h(v0)\n",
        "        for k in range(10):\n",
        "            _,hk = rbm.sample_h(vk)\n",
        "            _,vk = rbm.sample_v(hk)\n",
        "            vk[v0 < 0] = v0[v0 < 0]\n",
        "        phk,_ = rbm.sample_h(vk)\n",
        "        rbm.train(v0, vk, ph0, phk)\n",
        "        training_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
        "        s += 1.\n",
        "    print(\"Epoch: \"+str(epoch)+\", Loss: \"+str(training_loss/s))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: tensor(0.3702)\n",
            "Epoch: 2, Loss: tensor(0.2528)\n",
            "Epoch: 3, Loss: tensor(0.2490)\n",
            "Epoch: 4, Loss: tensor(0.2513)\n",
            "Epoch: 5, Loss: tensor(0.2466)\n",
            "Epoch: 6, Loss: tensor(0.2471)\n",
            "Epoch: 7, Loss: tensor(0.2472)\n",
            "Epoch: 8, Loss: tensor(0.2385)\n",
            "Epoch: 9, Loss: tensor(0.2484)\n",
            "Epoch: 10, Loss: tensor(0.2490)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MwPi9jwVRVS"
      },
      "source": [
        "## Evaluación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QesQL9DVWuY",
        "outputId": "ee709aa2-0829-4e9a-c9c5-461b5af73b46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "testing_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    v = training_set[id_user:id_user+1]\n",
        "    vt = test_set[id_user:id_user+1]\n",
        "    if len(vt[vt>=0]) > 0:\n",
        "        _,h = rbm.sample_h(v)\n",
        "        _,v = rbm.sample_v(h)\n",
        "        testing_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
        "        s += 1.\n",
        "        print(\"Testing Loss: \"+str(testing_loss/s))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Loss: tensor(0.2263)\n",
            "Testing Loss: tensor(0.2040)\n",
            "Testing Loss: tensor(0.3155)\n",
            "Testing Loss: tensor(0.2866)\n",
            "Testing Loss: tensor(0.3007)\n",
            "Testing Loss: tensor(0.2869)\n",
            "Testing Loss: tensor(0.2707)\n",
            "Testing Loss: tensor(0.2541)\n",
            "Testing Loss: tensor(0.2370)\n",
            "Testing Loss: tensor(0.2289)\n",
            "Testing Loss: tensor(0.2344)\n",
            "Testing Loss: tensor(0.2309)\n",
            "Testing Loss: tensor(0.2380)\n",
            "Testing Loss: tensor(0.2348)\n",
            "Testing Loss: tensor(0.2479)\n",
            "Testing Loss: tensor(0.2412)\n",
            "Testing Loss: tensor(0.2466)\n",
            "Testing Loss: tensor(0.2414)\n",
            "Testing Loss: tensor(0.2445)\n",
            "Testing Loss: tensor(0.2482)\n",
            "Testing Loss: tensor(0.2522)\n",
            "Testing Loss: tensor(0.2525)\n",
            "Testing Loss: tensor(0.2505)\n",
            "Testing Loss: tensor(0.2432)\n",
            "Testing Loss: tensor(0.2345)\n",
            "Testing Loss: tensor(0.2367)\n",
            "Testing Loss: tensor(0.2379)\n",
            "Testing Loss: tensor(0.2356)\n",
            "Testing Loss: tensor(0.2356)\n",
            "Testing Loss: tensor(0.2407)\n",
            "Testing Loss: tensor(0.2404)\n",
            "Testing Loss: tensor(0.2395)\n",
            "Testing Loss: tensor(0.2443)\n",
            "Testing Loss: tensor(0.2460)\n",
            "Testing Loss: tensor(0.2532)\n",
            "Testing Loss: tensor(0.2563)\n",
            "Testing Loss: tensor(0.2521)\n",
            "Testing Loss: tensor(0.2559)\n",
            "Testing Loss: tensor(0.2550)\n",
            "Testing Loss: tensor(0.2544)\n",
            "Testing Loss: tensor(0.2575)\n",
            "Testing Loss: tensor(0.2566)\n",
            "Testing Loss: tensor(0.2551)\n",
            "Testing Loss: tensor(0.2551)\n",
            "Testing Loss: tensor(0.2541)\n",
            "Testing Loss: tensor(0.2499)\n",
            "Testing Loss: tensor(0.2470)\n",
            "Testing Loss: tensor(0.2450)\n",
            "Testing Loss: tensor(0.2485)\n",
            "Testing Loss: tensor(0.2490)\n",
            "Testing Loss: tensor(0.2469)\n",
            "Testing Loss: tensor(0.2458)\n",
            "Testing Loss: tensor(0.2443)\n",
            "Testing Loss: tensor(0.2446)\n",
            "Testing Loss: tensor(0.2451)\n",
            "Testing Loss: tensor(0.2461)\n",
            "Testing Loss: tensor(0.2462)\n",
            "Testing Loss: tensor(0.2441)\n",
            "Testing Loss: tensor(0.2441)\n",
            "Testing Loss: tensor(0.2419)\n",
            "Testing Loss: tensor(0.2434)\n",
            "Testing Loss: tensor(0.2441)\n",
            "Testing Loss: tensor(0.2448)\n",
            "Testing Loss: tensor(0.2444)\n",
            "Testing Loss: tensor(0.2430)\n",
            "Testing Loss: tensor(0.2429)\n",
            "Testing Loss: tensor(0.2418)\n",
            "Testing Loss: tensor(0.2437)\n",
            "Testing Loss: tensor(0.2418)\n",
            "Testing Loss: tensor(0.2415)\n",
            "Testing Loss: tensor(0.2399)\n",
            "Testing Loss: tensor(0.2387)\n",
            "Testing Loss: tensor(0.2376)\n",
            "Testing Loss: tensor(0.2359)\n",
            "Testing Loss: tensor(0.2381)\n",
            "Testing Loss: tensor(0.2378)\n",
            "Testing Loss: tensor(0.2359)\n",
            "Testing Loss: tensor(0.2383)\n",
            "Testing Loss: tensor(0.2394)\n",
            "Testing Loss: tensor(0.2389)\n",
            "Testing Loss: tensor(0.2399)\n",
            "Testing Loss: tensor(0.2415)\n",
            "Testing Loss: tensor(0.2432)\n",
            "Testing Loss: tensor(0.2413)\n",
            "Testing Loss: tensor(0.2405)\n",
            "Testing Loss: tensor(0.2415)\n",
            "Testing Loss: tensor(0.2416)\n",
            "Testing Loss: tensor(0.2422)\n",
            "Testing Loss: tensor(0.2426)\n",
            "Testing Loss: tensor(0.2420)\n",
            "Testing Loss: tensor(0.2414)\n",
            "Testing Loss: tensor(0.2414)\n",
            "Testing Loss: tensor(0.2427)\n",
            "Testing Loss: tensor(0.2434)\n",
            "Testing Loss: tensor(0.2437)\n",
            "Testing Loss: tensor(0.2430)\n",
            "Testing Loss: tensor(0.2409)\n",
            "Testing Loss: tensor(0.2403)\n",
            "Testing Loss: tensor(0.2410)\n",
            "Testing Loss: tensor(0.2422)\n",
            "Testing Loss: tensor(0.2446)\n",
            "Testing Loss: tensor(0.2455)\n",
            "Testing Loss: tensor(0.2445)\n",
            "Testing Loss: tensor(0.2466)\n",
            "Testing Loss: tensor(0.2456)\n",
            "Testing Loss: tensor(0.2438)\n",
            "Testing Loss: tensor(0.2446)\n",
            "Testing Loss: tensor(0.2435)\n",
            "Testing Loss: tensor(0.2440)\n",
            "Testing Loss: tensor(0.2443)\n",
            "Testing Loss: tensor(0.2443)\n",
            "Testing Loss: tensor(0.2446)\n",
            "Testing Loss: tensor(0.2460)\n",
            "Testing Loss: tensor(0.2459)\n",
            "Testing Loss: tensor(0.2454)\n",
            "Testing Loss: tensor(0.2466)\n",
            "Testing Loss: tensor(0.2460)\n",
            "Testing Loss: tensor(0.2448)\n",
            "Testing Loss: tensor(0.2451)\n",
            "Testing Loss: tensor(0.2451)\n",
            "Testing Loss: tensor(0.2460)\n",
            "Testing Loss: tensor(0.2449)\n",
            "Testing Loss: tensor(0.2439)\n",
            "Testing Loss: tensor(0.2436)\n",
            "Testing Loss: tensor(0.2439)\n",
            "Testing Loss: tensor(0.2459)\n",
            "Testing Loss: tensor(0.2486)\n",
            "Testing Loss: tensor(0.2478)\n",
            "Testing Loss: tensor(0.2501)\n",
            "Testing Loss: tensor(0.2502)\n",
            "Testing Loss: tensor(0.2488)\n",
            "Testing Loss: tensor(0.2470)\n",
            "Testing Loss: tensor(0.2470)\n",
            "Testing Loss: tensor(0.2469)\n",
            "Testing Loss: tensor(0.2469)\n",
            "Testing Loss: tensor(0.2466)\n",
            "Testing Loss: tensor(0.2457)\n",
            "Testing Loss: tensor(0.2446)\n",
            "Testing Loss: tensor(0.2436)\n",
            "Testing Loss: tensor(0.2432)\n",
            "Testing Loss: tensor(0.2440)\n",
            "Testing Loss: tensor(0.2444)\n",
            "Testing Loss: tensor(0.2427)\n",
            "Testing Loss: tensor(0.2423)\n",
            "Testing Loss: tensor(0.2432)\n",
            "Testing Loss: tensor(0.2415)\n",
            "Testing Loss: tensor(0.2399)\n",
            "Testing Loss: tensor(0.2399)\n",
            "Testing Loss: tensor(0.2426)\n",
            "Testing Loss: tensor(0.2428)\n",
            "Testing Loss: tensor(0.2425)\n",
            "Testing Loss: tensor(0.2433)\n",
            "Testing Loss: tensor(0.2450)\n",
            "Testing Loss: tensor(0.2444)\n",
            "Testing Loss: tensor(0.2458)\n",
            "Testing Loss: tensor(0.2449)\n",
            "Testing Loss: tensor(0.2439)\n",
            "Testing Loss: tensor(0.2436)\n",
            "Testing Loss: tensor(0.2444)\n",
            "Testing Loss: tensor(0.2441)\n",
            "Testing Loss: tensor(0.2457)\n",
            "Testing Loss: tensor(0.2451)\n",
            "Testing Loss: tensor(0.2448)\n",
            "Testing Loss: tensor(0.2445)\n",
            "Testing Loss: tensor(0.2435)\n",
            "Testing Loss: tensor(0.2457)\n",
            "Testing Loss: tensor(0.2467)\n",
            "Testing Loss: tensor(0.2470)\n",
            "Testing Loss: tensor(0.2468)\n",
            "Testing Loss: tensor(0.2462)\n",
            "Testing Loss: tensor(0.2460)\n",
            "Testing Loss: tensor(0.2459)\n",
            "Testing Loss: tensor(0.2452)\n",
            "Testing Loss: tensor(0.2459)\n",
            "Testing Loss: tensor(0.2460)\n",
            "Testing Loss: tensor(0.2457)\n",
            "Testing Loss: tensor(0.2459)\n",
            "Testing Loss: tensor(0.2456)\n",
            "Testing Loss: tensor(0.2463)\n",
            "Testing Loss: tensor(0.2452)\n",
            "Testing Loss: tensor(0.2471)\n",
            "Testing Loss: tensor(0.2469)\n",
            "Testing Loss: tensor(0.2479)\n",
            "Testing Loss: tensor(0.2477)\n",
            "Testing Loss: tensor(0.2468)\n",
            "Testing Loss: tensor(0.2481)\n",
            "Testing Loss: tensor(0.2475)\n",
            "Testing Loss: tensor(0.2478)\n",
            "Testing Loss: tensor(0.2477)\n",
            "Testing Loss: tensor(0.2483)\n",
            "Testing Loss: tensor(0.2485)\n",
            "Testing Loss: tensor(0.2500)\n",
            "Testing Loss: tensor(0.2504)\n",
            "Testing Loss: tensor(0.2507)\n",
            "Testing Loss: tensor(0.2509)\n",
            "Testing Loss: tensor(0.2507)\n",
            "Testing Loss: tensor(0.2506)\n",
            "Testing Loss: tensor(0.2504)\n",
            "Testing Loss: tensor(0.2508)\n",
            "Testing Loss: tensor(0.2507)\n",
            "Testing Loss: tensor(0.2514)\n",
            "Testing Loss: tensor(0.2522)\n",
            "Testing Loss: tensor(0.2517)\n",
            "Testing Loss: tensor(0.2520)\n",
            "Testing Loss: tensor(0.2515)\n",
            "Testing Loss: tensor(0.2525)\n",
            "Testing Loss: tensor(0.2526)\n",
            "Testing Loss: tensor(0.2523)\n",
            "Testing Loss: tensor(0.2531)\n",
            "Testing Loss: tensor(0.2524)\n",
            "Testing Loss: tensor(0.2527)\n",
            "Testing Loss: tensor(0.2521)\n",
            "Testing Loss: tensor(0.2516)\n",
            "Testing Loss: tensor(0.2511)\n",
            "Testing Loss: tensor(0.2509)\n",
            "Testing Loss: tensor(0.2510)\n",
            "Testing Loss: tensor(0.2513)\n",
            "Testing Loss: tensor(0.2508)\n",
            "Testing Loss: tensor(0.2512)\n",
            "Testing Loss: tensor(0.2512)\n",
            "Testing Loss: tensor(0.2511)\n",
            "Testing Loss: tensor(0.2515)\n",
            "Testing Loss: tensor(0.2524)\n",
            "Testing Loss: tensor(0.2526)\n",
            "Testing Loss: tensor(0.2518)\n",
            "Testing Loss: tensor(0.2514)\n",
            "Testing Loss: tensor(0.2511)\n",
            "Testing Loss: tensor(0.2516)\n",
            "Testing Loss: tensor(0.2531)\n",
            "Testing Loss: tensor(0.2530)\n",
            "Testing Loss: tensor(0.2526)\n",
            "Testing Loss: tensor(0.2523)\n",
            "Testing Loss: tensor(0.2512)\n",
            "Testing Loss: tensor(0.2515)\n",
            "Testing Loss: tensor(0.2509)\n",
            "Testing Loss: tensor(0.2509)\n",
            "Testing Loss: tensor(0.2504)\n",
            "Testing Loss: tensor(0.2505)\n",
            "Testing Loss: tensor(0.2501)\n",
            "Testing Loss: tensor(0.2505)\n",
            "Testing Loss: tensor(0.2506)\n",
            "Testing Loss: tensor(0.2505)\n",
            "Testing Loss: tensor(0.2501)\n",
            "Testing Loss: tensor(0.2506)\n",
            "Testing Loss: tensor(0.2509)\n",
            "Testing Loss: tensor(0.2515)\n",
            "Testing Loss: tensor(0.2512)\n",
            "Testing Loss: tensor(0.2508)\n",
            "Testing Loss: tensor(0.2507)\n",
            "Testing Loss: tensor(0.2509)\n",
            "Testing Loss: tensor(0.2501)\n",
            "Testing Loss: tensor(0.2499)\n",
            "Testing Loss: tensor(0.2494)\n",
            "Testing Loss: tensor(0.2495)\n",
            "Testing Loss: tensor(0.2498)\n",
            "Testing Loss: tensor(0.2497)\n",
            "Testing Loss: tensor(0.2496)\n",
            "Testing Loss: tensor(0.2502)\n",
            "Testing Loss: tensor(0.2503)\n",
            "Testing Loss: tensor(0.2512)\n",
            "Testing Loss: tensor(0.2512)\n",
            "Testing Loss: tensor(0.2514)\n",
            "Testing Loss: tensor(0.2513)\n",
            "Testing Loss: tensor(0.2512)\n",
            "Testing Loss: tensor(0.2517)\n",
            "Testing Loss: tensor(0.2518)\n",
            "Testing Loss: tensor(0.2513)\n",
            "Testing Loss: tensor(0.2515)\n",
            "Testing Loss: tensor(0.2517)\n",
            "Testing Loss: tensor(0.2519)\n",
            "Testing Loss: tensor(0.2519)\n",
            "Testing Loss: tensor(0.2515)\n",
            "Testing Loss: tensor(0.2506)\n",
            "Testing Loss: tensor(0.2504)\n",
            "Testing Loss: tensor(0.2501)\n",
            "Testing Loss: tensor(0.2502)\n",
            "Testing Loss: tensor(0.2503)\n",
            "Testing Loss: tensor(0.2494)\n",
            "Testing Loss: tensor(0.2497)\n",
            "Testing Loss: tensor(0.2498)\n",
            "Testing Loss: tensor(0.2505)\n",
            "Testing Loss: tensor(0.2507)\n",
            "Testing Loss: tensor(0.2509)\n",
            "Testing Loss: tensor(0.2503)\n",
            "Testing Loss: tensor(0.2499)\n",
            "Testing Loss: tensor(0.2503)\n",
            "Testing Loss: tensor(0.2502)\n",
            "Testing Loss: tensor(0.2499)\n",
            "Testing Loss: tensor(0.2505)\n",
            "Testing Loss: tensor(0.2506)\n",
            "Testing Loss: tensor(0.2506)\n",
            "Testing Loss: tensor(0.2500)\n",
            "Testing Loss: tensor(0.2504)\n",
            "Testing Loss: tensor(0.2503)\n",
            "Testing Loss: tensor(0.2504)\n",
            "Testing Loss: tensor(0.2503)\n",
            "Testing Loss: tensor(0.2503)\n",
            "Testing Loss: tensor(0.2499)\n",
            "Testing Loss: tensor(0.2498)\n",
            "Testing Loss: tensor(0.2507)\n",
            "Testing Loss: tensor(0.2508)\n",
            "Testing Loss: tensor(0.2521)\n",
            "Testing Loss: tensor(0.2524)\n",
            "Testing Loss: tensor(0.2526)\n",
            "Testing Loss: tensor(0.2528)\n",
            "Testing Loss: tensor(0.2523)\n",
            "Testing Loss: tensor(0.2522)\n",
            "Testing Loss: tensor(0.2520)\n",
            "Testing Loss: tensor(0.2522)\n",
            "Testing Loss: tensor(0.2522)\n",
            "Testing Loss: tensor(0.2520)\n",
            "Testing Loss: tensor(0.2518)\n",
            "Testing Loss: tensor(0.2519)\n",
            "Testing Loss: tensor(0.2521)\n",
            "Testing Loss: tensor(0.2517)\n",
            "Testing Loss: tensor(0.2516)\n",
            "Testing Loss: tensor(0.2511)\n",
            "Testing Loss: tensor(0.2512)\n",
            "Testing Loss: tensor(0.2509)\n",
            "Testing Loss: tensor(0.2510)\n",
            "Testing Loss: tensor(0.2505)\n",
            "Testing Loss: tensor(0.2501)\n",
            "Testing Loss: tensor(0.2500)\n",
            "Testing Loss: tensor(0.2501)\n",
            "Testing Loss: tensor(0.2501)\n",
            "Testing Loss: tensor(0.2499)\n",
            "Testing Loss: tensor(0.2500)\n",
            "Testing Loss: tensor(0.2499)\n",
            "Testing Loss: tensor(0.2495)\n",
            "Testing Loss: tensor(0.2494)\n",
            "Testing Loss: tensor(0.2493)\n",
            "Testing Loss: tensor(0.2490)\n",
            "Testing Loss: tensor(0.2485)\n",
            "Testing Loss: tensor(0.2483)\n",
            "Testing Loss: tensor(0.2483)\n",
            "Testing Loss: tensor(0.2487)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2487)\n",
            "Testing Loss: tensor(0.2484)\n",
            "Testing Loss: tensor(0.2480)\n",
            "Testing Loss: tensor(0.2486)\n",
            "Testing Loss: tensor(0.2489)\n",
            "Testing Loss: tensor(0.2487)\n",
            "Testing Loss: tensor(0.2485)\n",
            "Testing Loss: tensor(0.2486)\n",
            "Testing Loss: tensor(0.2489)\n",
            "Testing Loss: tensor(0.2493)\n",
            "Testing Loss: tensor(0.2494)\n",
            "Testing Loss: tensor(0.2502)\n",
            "Testing Loss: tensor(0.2497)\n",
            "Testing Loss: tensor(0.2502)\n",
            "Testing Loss: tensor(0.2499)\n",
            "Testing Loss: tensor(0.2499)\n",
            "Testing Loss: tensor(0.2498)\n",
            "Testing Loss: tensor(0.2496)\n",
            "Testing Loss: tensor(0.2498)\n",
            "Testing Loss: tensor(0.2496)\n",
            "Testing Loss: tensor(0.2499)\n",
            "Testing Loss: tensor(0.2499)\n",
            "Testing Loss: tensor(0.2494)\n",
            "Testing Loss: tensor(0.2492)\n",
            "Testing Loss: tensor(0.2501)\n",
            "Testing Loss: tensor(0.2503)\n",
            "Testing Loss: tensor(0.2505)\n",
            "Testing Loss: tensor(0.2505)\n",
            "Testing Loss: tensor(0.2505)\n",
            "Testing Loss: tensor(0.2505)\n",
            "Testing Loss: tensor(0.2509)\n",
            "Testing Loss: tensor(0.2502)\n",
            "Testing Loss: tensor(0.2500)\n",
            "Testing Loss: tensor(0.2493)\n",
            "Testing Loss: tensor(0.2496)\n",
            "Testing Loss: tensor(0.2494)\n",
            "Testing Loss: tensor(0.2497)\n",
            "Testing Loss: tensor(0.2497)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2494)\n",
            "Testing Loss: tensor(0.2493)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2490)\n",
            "Testing Loss: tensor(0.2493)\n",
            "Testing Loss: tensor(0.2496)\n",
            "Testing Loss: tensor(0.2493)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2493)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2487)\n",
            "Testing Loss: tensor(0.2485)\n",
            "Testing Loss: tensor(0.2488)\n",
            "Testing Loss: tensor(0.2487)\n",
            "Testing Loss: tensor(0.2487)\n",
            "Testing Loss: tensor(0.2490)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2489)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2487)\n",
            "Testing Loss: tensor(0.2487)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2492)\n",
            "Testing Loss: tensor(0.2489)\n",
            "Testing Loss: tensor(0.2483)\n",
            "Testing Loss: tensor(0.2489)\n",
            "Testing Loss: tensor(0.2496)\n",
            "Testing Loss: tensor(0.2495)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2485)\n",
            "Testing Loss: tensor(0.2488)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2491)\n",
            "Testing Loss: tensor(0.2490)\n",
            "Testing Loss: tensor(0.2494)\n",
            "Testing Loss: tensor(0.2504)\n",
            "Testing Loss: tensor(0.2498)\n",
            "Testing Loss: tensor(0.2498)\n",
            "Testing Loss: tensor(0.2501)\n",
            "Testing Loss: tensor(0.2495)\n",
            "Testing Loss: tensor(0.2489)\n",
            "Testing Loss: tensor(0.2483)\n",
            "Testing Loss: tensor(0.2477)\n",
            "Testing Loss: tensor(0.2476)\n",
            "Testing Loss: tensor(0.2472)\n",
            "Testing Loss: tensor(0.2466)\n",
            "Testing Loss: tensor(0.2471)\n",
            "Testing Loss: tensor(0.2467)\n",
            "Testing Loss: tensor(0.2461)\n",
            "Testing Loss: tensor(0.2462)\n",
            "Testing Loss: tensor(0.2462)\n",
            "Testing Loss: tensor(0.2456)\n",
            "Testing Loss: tensor(0.2458)\n",
            "Testing Loss: tensor(0.2459)\n",
            "Testing Loss: tensor(0.2459)\n",
            "Testing Loss: tensor(0.2461)\n",
            "Testing Loss: tensor(0.2462)\n",
            "Testing Loss: tensor(0.2461)\n",
            "Testing Loss: tensor(0.2462)\n",
            "Testing Loss: tensor(0.2468)\n",
            "Testing Loss: tensor(0.2462)\n",
            "Testing Loss: tensor(0.2464)\n",
            "Testing Loss: tensor(0.2466)\n",
            "Testing Loss: tensor(0.2475)\n",
            "Testing Loss: tensor(0.2484)\n",
            "Testing Loss: tensor(0.2478)\n",
            "Testing Loss: tensor(0.2476)\n",
            "Testing Loss: tensor(0.2478)\n",
            "Testing Loss: tensor(0.2481)\n",
            "Testing Loss: tensor(0.2477)\n",
            "Testing Loss: tensor(0.2481)\n",
            "Testing Loss: tensor(0.2485)\n",
            "Testing Loss: tensor(0.2486)\n",
            "Testing Loss: tensor(0.2488)\n",
            "Testing Loss: tensor(0.2487)\n",
            "Testing Loss: tensor(0.2493)\n",
            "Testing Loss: tensor(0.2490)\n",
            "Testing Loss: tensor(0.2484)\n",
            "Testing Loss: tensor(0.2479)\n",
            "Testing Loss: tensor(0.2474)\n",
            "Testing Loss: tensor(0.2490)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}