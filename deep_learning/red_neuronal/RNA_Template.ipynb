{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNA_Template",
      "provenance": [],
      "authorship_tag": "ABX9TyOATuUposeyvbP2HGljSm5Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cccg8105/notebook_AD/blob/deep_learning/deep_learning/red_neuronal/RNA_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR0DA3dJY2nG"
      },
      "source": [
        "\n",
        "# Red Neuronal Artificial (RNA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8VFu75ZD3f"
      },
      "source": [
        "## Instalar dependendias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5IS_myMVCBp",
        "outputId": "451e54ad-34fa-4bf5-ad18-02a1a67dc1fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install sklearn\n",
        "!pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
        "!pip install keras\n",
        "!pip install tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Collecting git+git://github.com/Theano/Theano.git\n",
            "  Cloning git://github.com/Theano/Theano.git to /tmp/pip-req-build-8izjgd65\n",
            "  Running command git clone -q git://github.com/Theano/Theano.git /tmp/pip-req-build-8izjgd65\n",
            "Building wheels for collected packages: Theano\n",
            "  Building wheel for Theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano: filename=Theano-1.0.5+1.geb6a4125c-cp36-none-any.whl size=2668281 sha256=0da1a6ea0e3aaa9c2bdba1b488919383295d3096efb490a7d7640621318b70c9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-izzmrh_h/wheels/ae/32/7c/62beb8371953eb20c271b3bac7d0e56e1a2020d46994346b52\n",
            "Successfully built Theano\n",
            "Installing collected packages: Theano\n",
            "  Found existing installation: Theano 1.0.5\n",
            "    Uninstalling Theano-1.0.5:\n",
            "      Successfully uninstalled Theano-1.0.5\n",
            "Successfully installed Theano-1.0.5+1.geb6a4125c\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUyj_SatZdVN"
      },
      "source": [
        "## Importar conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VLHVlPfZkv_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/cccg8105/deeplearning-az/master/datasets/Part%201%20-%20Artificial%20Neural%20Networks%20(ANN)/Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:13].values\n",
        "y = dataset.iloc[:, 13].values"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3jrBmgeaak7"
      },
      "source": [
        "## Preprocesado de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSWC-WB3bP5u"
      },
      "source": [
        "### Conversión de datos categóricos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ViXj0Prad_w"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
        "onehotencoder = ColumnTransformer(\n",
        "    [('one_hot_encoder', OneHotEncoder(categories='auto'), [1])],   \n",
        "    remainder='passthrough'                        \n",
        ")\n",
        "X = onehotencoder.fit_transform(X)\n",
        "X = X[:, 1:]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajbXl7mMbCOs"
      },
      "source": [
        "### Dividir en entrenamiento y prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcabzICsbIV9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSA5sMkYbZ_1"
      },
      "source": [
        "### Escalado de variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLtGEsagbeve"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAltaDvAb2K1"
      },
      "source": [
        "## Construcción"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znIlucgub533"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout # implementa el olvido en las neuronas para evitar sobre ajuste \n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "# Añadir las capas de entrada y primera capa oculta\n",
        "nodosIniciales = 6 # se recomienda poner la media entre los nodos de entrada y salida (11+1)/2\n",
        "inicializadorKernel = \"uniform\" # glorot_uniform|||\n",
        "funcionActivacion = \"relu\" # funcion escalon|funcion sigmoide(sigmoid)|tangente hiperbolica(tanh)| rectificador lineal(relu)\n",
        "nodosEntrada = 11 # numero de variables en la matriz de caracteristicas\n",
        "\n",
        "classifier.add(Dense(units = nodosIniciales, kernel_initializer = inicializadorKernel,  \n",
        "                     activation = funcionActivacion, input_dim = nodosEntrada))\n",
        "\n",
        "# Añadir la segunda capa oculta\n",
        "nodosCapa2 = 6\n",
        "inicializadorKernel2 = \"uniform\" \n",
        "funcionActivacion2 = \"relu\" \n",
        "classifier.add(Dense(units = nodosCapa2, kernel_initializer = inicializadorKernel2,  activation = funcionActivacion2))\n",
        "\n",
        "# Capa de olvido\n",
        "ratioDesactivacion = 0.1 # porcentaje de nodos desactivados <= 0.5\n",
        "classifier.add(Dropout(rate = ratioDesactivacion))\n",
        "\n",
        "# Añadir la capa de salida\n",
        "nodoSalida = 1\n",
        "salidaKernel = \"uniform\" \n",
        "funcionActivacionSalida = \"sigmoid\" \n",
        "classifier.add(Dense(units = nodoSalida, kernel_initializer = salidaKernel,  activation = funcionActivacionSalida))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf85QdCniM2d"
      },
      "source": [
        "## Compilación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j_tB0XGiL6f"
      },
      "source": [
        "optimizador = \"adam\" # |||\n",
        "funcionPerdida =  \"binary_crossentropy\" # softmax|||\n",
        "metricas = [\"accuracy\"] # |||\n",
        "classifier.compile(optimizer = optimizador, loss = funcionPerdida, metrics = metricas)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WadAY9tjc5R"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZHYKPw7nIV5",
        "outputId": "0be4fb0b-bd71-415c-82da-700851e8c704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tamanioLote = 10\n",
        "epocas = 100\n",
        "classifier.fit(X_train, y_train,  batch_size = tamanioLote, epochs = epocas)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "800/800 [==============================] - 1s 870us/step - loss: 0.4846 - accuracy: 0.7956\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 1s 980us/step - loss: 0.4309 - accuracy: 0.7960\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 1s 900us/step - loss: 0.4256 - accuracy: 0.7960\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 1s 913us/step - loss: 0.4229 - accuracy: 0.8179\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 1s 871us/step - loss: 0.4210 - accuracy: 0.8271\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 1s 912us/step - loss: 0.4217 - accuracy: 0.8305\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 1s 983us/step - loss: 0.4208 - accuracy: 0.8304\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 1s 886us/step - loss: 0.4183 - accuracy: 0.8309\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 1s 875us/step - loss: 0.4188 - accuracy: 0.8325\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 1s 888us/step - loss: 0.4162 - accuracy: 0.8309\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 1s 897us/step - loss: 0.4184 - accuracy: 0.8338\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 1s 896us/step - loss: 0.4189 - accuracy: 0.8347\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 1s 851us/step - loss: 0.4160 - accuracy: 0.8320\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 1s 871us/step - loss: 0.4162 - accuracy: 0.8326\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 1s 882us/step - loss: 0.4163 - accuracy: 0.8328\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 1s 913us/step - loss: 0.4178 - accuracy: 0.8328\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 1s 889us/step - loss: 0.4177 - accuracy: 0.8331\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 1s 887us/step - loss: 0.4170 - accuracy: 0.8351\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 1s 916us/step - loss: 0.4172 - accuracy: 0.8335\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 1s 915us/step - loss: 0.4162 - accuracy: 0.8338\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 1s 876us/step - loss: 0.4169 - accuracy: 0.8320\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 1s 941us/step - loss: 0.4151 - accuracy: 0.8341\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 1s 910us/step - loss: 0.4160 - accuracy: 0.8311\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 1s 898us/step - loss: 0.4170 - accuracy: 0.8319\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 1s 904us/step - loss: 0.4180 - accuracy: 0.8326\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 1s 907us/step - loss: 0.4175 - accuracy: 0.8317\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 1s 896us/step - loss: 0.4146 - accuracy: 0.8325\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 1s 871us/step - loss: 0.4155 - accuracy: 0.8336\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 1s 896us/step - loss: 0.4139 - accuracy: 0.8330\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 1s 902us/step - loss: 0.4152 - accuracy: 0.8326\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 1s 880us/step - loss: 0.4114 - accuracy: 0.8335\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 1s 903us/step - loss: 0.4119 - accuracy: 0.8340\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 1s 961us/step - loss: 0.4146 - accuracy: 0.8317\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 1s 914us/step - loss: 0.4148 - accuracy: 0.8342\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 1s 914us/step - loss: 0.4155 - accuracy: 0.8313\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 1s 899us/step - loss: 0.4154 - accuracy: 0.8321\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 1s 879us/step - loss: 0.4143 - accuracy: 0.8341\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 1s 904us/step - loss: 0.4139 - accuracy: 0.8313\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 1s 884us/step - loss: 0.4162 - accuracy: 0.8311\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 1s 892us/step - loss: 0.4121 - accuracy: 0.8325\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 1s 892us/step - loss: 0.4118 - accuracy: 0.8325\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 1s 922us/step - loss: 0.4124 - accuracy: 0.8320\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 1s 893us/step - loss: 0.4153 - accuracy: 0.8341\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 1s 909us/step - loss: 0.4149 - accuracy: 0.8306\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 1s 913us/step - loss: 0.4139 - accuracy: 0.8319\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 1s 910us/step - loss: 0.4137 - accuracy: 0.8347\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 1s 901us/step - loss: 0.4135 - accuracy: 0.8341\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 1s 940us/step - loss: 0.4148 - accuracy: 0.8325\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4154 - accuracy: 0.8300\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4150 - accuracy: 0.8320\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4134 - accuracy: 0.8301\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4120 - accuracy: 0.8331\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4118 - accuracy: 0.8328\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4125 - accuracy: 0.8320\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4125 - accuracy: 0.8322\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4129 - accuracy: 0.8329\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4119 - accuracy: 0.8330\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4110 - accuracy: 0.8328\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4101 - accuracy: 0.8339\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 1s 907us/step - loss: 0.4113 - accuracy: 0.8334\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 1s 957us/step - loss: 0.4064 - accuracy: 0.8335\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 1s 913us/step - loss: 0.4124 - accuracy: 0.8325\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 1s 905us/step - loss: 0.4070 - accuracy: 0.8349\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 1s 923us/step - loss: 0.4067 - accuracy: 0.8356\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 1s 928us/step - loss: 0.4084 - accuracy: 0.8345\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 1s 920us/step - loss: 0.4091 - accuracy: 0.8370\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 1s 912us/step - loss: 0.4062 - accuracy: 0.8356\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 1s 897us/step - loss: 0.4058 - accuracy: 0.8341\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 1s 963us/step - loss: 0.4074 - accuracy: 0.8355\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 1s 921us/step - loss: 0.4072 - accuracy: 0.8347\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 1s 908us/step - loss: 0.4053 - accuracy: 0.8353\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 1s 918us/step - loss: 0.4058 - accuracy: 0.8354\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 1s 929us/step - loss: 0.4045 - accuracy: 0.8361\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 1s 908us/step - loss: 0.4054 - accuracy: 0.8360\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 1s 908us/step - loss: 0.4032 - accuracy: 0.8356\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 1s 909us/step - loss: 0.4027 - accuracy: 0.8360\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 1s 926us/step - loss: 0.4054 - accuracy: 0.8355\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4025 - accuracy: 0.8357\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4029 - accuracy: 0.8353\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4042 - accuracy: 0.8357\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4026 - accuracy: 0.8339\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4022 - accuracy: 0.8341\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4025 - accuracy: 0.8356\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4054 - accuracy: 0.8313\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 1s 923us/step - loss: 0.4009 - accuracy: 0.8349\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 1s 883us/step - loss: 0.4017 - accuracy: 0.8294\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 1s 889us/step - loss: 0.4030 - accuracy: 0.8346\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 1s 910us/step - loss: 0.4015 - accuracy: 0.8313\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 1s 895us/step - loss: 0.4023 - accuracy: 0.8328\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4016 - accuracy: 0.8345\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 1s 989us/step - loss: 0.4003 - accuracy: 0.8324\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 1s 982us/step - loss: 0.4009 - accuracy: 0.8313\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4012 - accuracy: 0.8314\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 1s 998us/step - loss: 0.4039 - accuracy: 0.8324\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4009 - accuracy: 0.8320\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 1s 994us/step - loss: 0.4042 - accuracy: 0.8313\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 1s 966us/step - loss: 0.4003 - accuracy: 0.8354\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 1s 920us/step - loss: 0.4018 - accuracy: 0.8330\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 1s 870us/step - loss: 0.4019 - accuracy: 0.8325\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 1s 872us/step - loss: 0.4017 - accuracy: 0.8331\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8ba80b1828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBbTsCyDpX6z"
      },
      "source": [
        "## Evaluar modelo con datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdkDPaMZpbjw",
        "outputId": "7770066f-15a7-452f-c009-8e1c56280b3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred  = classifier.predict(X_test)\n",
        "y_pred = (y_pred>0.5)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[752, 843],\n",
              "       [206, 199]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfl28FdEqM7c"
      },
      "source": [
        "## Mejorar y ajustar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFIkbex1swbG"
      },
      "source": [
        "### Evaluación K-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEcw09IUqPpt",
        "outputId": "b55bc071-66b6-40b5-9e1c-faf49716c0f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def build_classifier():\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Dense(units = nodosIniciales, kernel_initializer = inicializadorKernel, activation = funcionActivacion, input_dim = nodosEntrada))\n",
        "  classifier.add(Dense(units = nodosCapa2, kernel_initializer = inicializadorKernel2, activation = funcionActivacion2))\n",
        "  classifier.add(Dense(units = nodoSalida, kernel_initializer = salidaKernel, activation = funcionActivacionSalida))\n",
        "  classifier.compile(optimizer = optimizador, loss = funcionPerdida, metrics = metricas)\n",
        "  return classifier\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier, batch_size = tamanioLote, nb_epoch = epocas)\n",
        "\n",
        "tamanioBloqueEntrenamiento = 10\n",
        "tareasSimultaneas = -1 # usa todas las cpus de la pc\n",
        "mostrarDatosIntermedios = 1\n",
        "accuracies = cross_val_score(estimator=classifier, X = X_train, y = y_train, cv = tamanioBloqueEntrenamiento, \n",
        "                             n_jobs= tareasSimultaneas, verbose = mostrarDatosIntermedios)\n",
        "\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()\n",
        "\n",
        "print(mean)\n",
        "print(variance)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7960000097751617\n",
            "0.010105690527913859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   13.3s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGMPdJYgxVuS"
      },
      "source": [
        "Si las varianzas son muy altas es probable que exista overfitting:\n",
        "\n",
        "- Alto sesgo, baja varianza:\n",
        "- Alto sesgo, alta varianza:\n",
        "- Bajo sesgo, baja varianza: tiene buena precision y poca varianza. Esto es lo mejor\n",
        "- Bajo sesgo, alta varianza: buena precision pero mucha varianza. Es ideal disminuir la varianza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bTNevPVs11u"
      },
      "source": [
        "### Ajuste de hiperparametros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdnWMoSqs38L",
        "outputId": "ef41963c-d2f6-4723-cef2-e3e10d68428d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def build_classifier(optimizer):\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Dense(units = nodosIniciales, kernel_initializer = inicializadorKernel,  activation = funcionActivacion, input_dim = nodosEntrada))\n",
        "  classifier.add(Dense(units = nodosCapa2, kernel_initializer = inicializadorKernel2,  activation = funcionActivacion2))\n",
        "  classifier.add(Dense(units = nodoSalida, kernel_initializer = salidaKernel,  activation = funcionActivacionSalida))\n",
        "  classifier.compile(optimizer = optimizer, loss = funcionPerdida, metrics = metricas)\n",
        "  return classifier\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "\n",
        "rangoLotes = [10,32]\n",
        "rangoEpocas = [80, 100, 120]\n",
        "optimizadores = ['adam', 'rmsprop']\n",
        "parameters = {\n",
        "    'batch_size' : rangoLotes,\n",
        "    'nb_epoch' : rangoEpocas, \n",
        "    'optimizer' : optimizadores\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator = classifier, \n",
        "                           param_grid = parameters, \n",
        "                           scoring = 'accuracy', \n",
        "                           cv = tamanioBloqueEntrenamiento)\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_parameters = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_\n",
        "\n",
        "print(best_parameters)\n",
        "print(best_accuracy)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "720/720 [==============================] - 1s 944us/step - loss: 0.4857 - accuracy: 0.7969\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "720/720 [==============================] - 1s 853us/step - loss: 0.4962 - accuracy: 0.7962\n",
            "720/720 [==============================] - 1s 953us/step - loss: 0.4854 - accuracy: 0.7954\n",
            "720/720 [==============================] - 1s 851us/step - loss: 0.4877 - accuracy: 0.7971\n",
            "720/720 [==============================] - 1s 904us/step - loss: 0.4896 - accuracy: 0.7931\n",
            "720/720 [==============================] - 1s 885us/step - loss: 0.5129 - accuracy: 0.7942\n",
            "720/720 [==============================] - 1s 880us/step - loss: 0.4993 - accuracy: 0.7971\n",
            "720/720 [==============================] - 1s 858us/step - loss: 0.5024 - accuracy: 0.7953\n",
            "720/720 [==============================] - 1s 860us/step - loss: 0.4936 - accuracy: 0.7946\n",
            "720/720 [==============================] - 1s 849us/step - loss: 0.4949 - accuracy: 0.7960\n",
            "720/720 [==============================] - 1s 899us/step - loss: 0.5005 - accuracy: 0.7964\n",
            "720/720 [==============================] - 1s 892us/step - loss: 0.5078 - accuracy: 0.7960\n",
            "720/720 [==============================] - 1s 884us/step - loss: 0.5149 - accuracy: 0.7951\n",
            "720/720 [==============================] - 1s 861us/step - loss: 0.4983 - accuracy: 0.7971\n",
            "720/720 [==============================] - 1s 902us/step - loss: 0.5132 - accuracy: 0.7936\n",
            "720/720 [==============================] - 1s 962us/step - loss: 0.4980 - accuracy: 0.7935\n",
            "720/720 [==============================] - 1s 863us/step - loss: 0.4988 - accuracy: 0.7969\n",
            "720/720 [==============================] - 1s 925us/step - loss: 0.5105 - accuracy: 0.7958\n",
            "720/720 [==============================] - 1s 883us/step - loss: 0.5128 - accuracy: 0.7953\n",
            "720/720 [==============================] - 1s 886us/step - loss: 0.5015 - accuracy: 0.7957\n",
            "720/720 [==============================] - 1s 876us/step - loss: 0.4949 - accuracy: 0.7969\n",
            "720/720 [==============================] - 1s 872us/step - loss: 0.4919 - accuracy: 0.7960\n",
            "720/720 [==============================] - 1s 881us/step - loss: 0.4903 - accuracy: 0.7944\n",
            "720/720 [==============================] - 1s 929us/step - loss: 0.5038 - accuracy: 0.7976\n",
            "720/720 [==============================] - 1s 872us/step - loss: 0.4848 - accuracy: 0.7937\n",
            "720/720 [==============================] - 1s 885us/step - loss: 0.4949 - accuracy: 0.7940\n",
            "720/720 [==============================] - 1s 891us/step - loss: 0.4866 - accuracy: 0.7969\n",
            "720/720 [==============================] - 1s 860us/step - loss: 0.4808 - accuracy: 0.7962\n",
            "720/720 [==============================] - 1s 879us/step - loss: 0.4836 - accuracy: 0.7954\n",
            "720/720 [==============================] - 1s 896us/step - loss: 0.4907 - accuracy: 0.7960\n",
            "720/720 [==============================] - 1s 947us/step - loss: 0.5095 - accuracy: 0.7971\n",
            "720/720 [==============================] - 1s 875us/step - loss: 0.4974 - accuracy: 0.7964\n",
            "720/720 [==============================] - 1s 875us/step - loss: 0.5173 - accuracy: 0.7954\n",
            "720/720 [==============================] - 1s 889us/step - loss: 0.4996 - accuracy: 0.7975\n",
            "720/720 [==============================] - 1s 896us/step - loss: 0.5055 - accuracy: 0.7935\n",
            "720/720 [==============================] - 1s 898us/step - loss: 0.5095 - accuracy: 0.7939\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5076 - accuracy: 0.7969\n",
            "720/720 [==============================] - 1s 882us/step - loss: 0.4997 - accuracy: 0.7962\n",
            "720/720 [==============================] - 1s 885us/step - loss: 0.5179 - accuracy: 0.7950\n",
            "720/720 [==============================] - 1s 880us/step - loss: 0.5128 - accuracy: 0.7954\n",
            "720/720 [==============================] - 1s 867us/step - loss: 0.4848 - accuracy: 0.7968\n",
            "720/720 [==============================] - 1s 933us/step - loss: 0.4911 - accuracy: 0.7967\n",
            "720/720 [==============================] - 1s 1000us/step - loss: 0.4951 - accuracy: 0.7951\n",
            "720/720 [==============================] - 1s 969us/step - loss: 0.4803 - accuracy: 0.7975\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.5132 - accuracy: 0.7932\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.4962 - accuracy: 0.7942\n",
            "720/720 [==============================] - 1s 903us/step - loss: 0.4836 - accuracy: 0.7969\n",
            "720/720 [==============================] - 1s 858us/step - loss: 0.4843 - accuracy: 0.7960\n",
            "720/720 [==============================] - 1s 878us/step - loss: 0.4852 - accuracy: 0.7956\n",
            "720/720 [==============================] - 1s 925us/step - loss: 0.4871 - accuracy: 0.7961\n",
            "720/720 [==============================] - 1s 895us/step - loss: 0.5115 - accuracy: 0.7962\n",
            "720/720 [==============================] - 1s 874us/step - loss: 0.5017 - accuracy: 0.7962\n",
            "720/720 [==============================] - 1s 875us/step - loss: 0.4988 - accuracy: 0.7956\n",
            "720/720 [==============================] - 1s 878us/step - loss: 0.5054 - accuracy: 0.7972\n",
            "720/720 [==============================] - 1s 929us/step - loss: 0.5163 - accuracy: 0.7937\n",
            "720/720 [==============================] - 1s 946us/step - loss: 0.5092 - accuracy: 0.7936\n",
            "720/720 [==============================] - 1s 930us/step - loss: 0.5118 - accuracy: 0.7971\n",
            "720/720 [==============================] - 1s 880us/step - loss: 0.5093 - accuracy: 0.7958\n",
            "720/720 [==============================] - 1s 922us/step - loss: 0.5024 - accuracy: 0.7946\n",
            "720/720 [==============================] - 1s 892us/step - loss: 0.5086 - accuracy: 0.7956\n",
            "225/225 [==============================] - 0s 918us/step - loss: 0.5717 - accuracy: 0.7969\n",
            "225/225 [==============================] - 0s 945us/step - loss: 0.5720 - accuracy: 0.7965\n",
            "225/225 [==============================] - 0s 928us/step - loss: 0.5847 - accuracy: 0.7949\n",
            "225/225 [==============================] - 0s 890us/step - loss: 0.5701 - accuracy: 0.7975\n",
            "225/225 [==============================] - 0s 998us/step - loss: 0.6075 - accuracy: 0.7925\n",
            "225/225 [==============================] - 0s 917us/step - loss: 0.5964 - accuracy: 0.7928\n",
            "225/225 [==============================] - 0s 957us/step - loss: 0.6146 - accuracy: 0.7946\n",
            "225/225 [==============================] - 0s 901us/step - loss: 0.5888 - accuracy: 0.7954\n",
            "225/225 [==============================] - 0s 928us/step - loss: 0.6092 - accuracy: 0.7943\n",
            "225/225 [==============================] - 0s 898us/step - loss: 0.5826 - accuracy: 0.7951\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.7964\n",
            "225/225 [==============================] - 0s 930us/step - loss: 0.5994 - accuracy: 0.7964\n",
            "225/225 [==============================] - 0s 993us/step - loss: 0.5975 - accuracy: 0.7954\n",
            "225/225 [==============================] - 0s 887us/step - loss: 0.5977 - accuracy: 0.7978\n",
            "225/225 [==============================] - 0s 917us/step - loss: 0.6109 - accuracy: 0.7921\n",
            "225/225 [==============================] - 0s 935us/step - loss: 0.6256 - accuracy: 0.7919\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6437 - accuracy: 0.7936\n",
            "225/225 [==============================] - 0s 891us/step - loss: 0.5737 - accuracy: 0.7962\n",
            "225/225 [==============================] - 0s 895us/step - loss: 0.5943 - accuracy: 0.7946\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6042 - accuracy: 0.7936\n",
            "225/225 [==============================] - 0s 958us/step - loss: 0.5793 - accuracy: 0.7961\n",
            "225/225 [==============================] - 0s 984us/step - loss: 0.6146 - accuracy: 0.7944\n",
            "225/225 [==============================] - 0s 944us/step - loss: 0.5809 - accuracy: 0.7956\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5918 - accuracy: 0.7956\n",
            "225/225 [==============================] - 0s 935us/step - loss: 0.5806 - accuracy: 0.7928\n",
            "225/225 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7949\n",
            "225/225 [==============================] - 0s 961us/step - loss: 0.6342 - accuracy: 0.7954\n",
            "225/225 [==============================] - 0s 868us/step - loss: 0.6150 - accuracy: 0.7935\n",
            "225/225 [==============================] - 0s 995us/step - loss: 0.5983 - accuracy: 0.7937\n",
            "225/225 [==============================] - 0s 894us/step - loss: 0.5844 - accuracy: 0.7956\n",
            "225/225 [==============================] - 0s 961us/step - loss: 0.6286 - accuracy: 0.7958\n",
            "225/225 [==============================] - 0s 905us/step - loss: 0.6196 - accuracy: 0.7950\n",
            "225/225 [==============================] - 0s 963us/step - loss: 0.5966 - accuracy: 0.7951\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6023 - accuracy: 0.7949\n",
            "225/225 [==============================] - 0s 930us/step - loss: 0.6167 - accuracy: 0.7931\n",
            "225/225 [==============================] - 0s 913us/step - loss: 0.6263 - accuracy: 0.7924\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.7951\n",
            "225/225 [==============================] - 0s 888us/step - loss: 0.6060 - accuracy: 0.7935\n",
            "225/225 [==============================] - 0s 980us/step - loss: 0.5883 - accuracy: 0.7957\n",
            "225/225 [==============================] - 0s 964us/step - loss: 0.6088 - accuracy: 0.7944\n",
            "225/225 [==============================] - 0s 904us/step - loss: 0.6088 - accuracy: 0.7958\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5867 - accuracy: 0.7956\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.7919\n",
            "225/225 [==============================] - 0s 999us/step - loss: 0.5919 - accuracy: 0.7960\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6098 - accuracy: 0.7915\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7944\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5953 - accuracy: 0.7958\n",
            "225/225 [==============================] - 0s 988us/step - loss: 0.5833 - accuracy: 0.7954\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6065 - accuracy: 0.7939\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6002 - accuracy: 0.7942\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5972 - accuracy: 0.7967\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5976 - accuracy: 0.7961\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6190 - accuracy: 0.7940\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6206 - accuracy: 0.7958\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.7937\n",
            "225/225 [==============================] - 0s 937us/step - loss: 0.5889 - accuracy: 0.7942\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5995 - accuracy: 0.7965\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6228 - accuracy: 0.7943\n",
            "225/225 [==============================] - 0s 947us/step - loss: 0.6109 - accuracy: 0.7944\n",
            "225/225 [==============================] - 0s 888us/step - loss: 0.5864 - accuracy: 0.7961\n",
            "800/800 [==============================] - 1s 930us/step - loss: 0.4857 - accuracy: 0.7954\n",
            "{'batch_size': 10, 'nb_epoch': 80, 'optimizer': 'adam'}\n",
            "0.799\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}