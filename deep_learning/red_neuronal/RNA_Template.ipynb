{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNA_Template",
      "provenance": [],
      "authorship_tag": "ABX9TyNo3CvzH7DIyUE/iSiuc0Y0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cccg8105/notebook_AD/blob/deep_learning/deep_learning/red_neuronal/RNA_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR0DA3dJY2nG"
      },
      "source": [
        "\n",
        "# Red Neuronal Artificial (RNA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8VFu75ZD3f"
      },
      "source": [
        "## Instalar dependendias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5IS_myMVCBp",
        "outputId": "3bda797d-7d4c-4d28-835e-28fed7534c06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install sklearn\n",
        "!pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
        "!pip install keras\n",
        "!pip install tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Collecting git+git://github.com/Theano/Theano.git\n",
            "  Cloning git://github.com/Theano/Theano.git to /tmp/pip-req-build-kuz_8k0r\n",
            "  Running command git clone -q git://github.com/Theano/Theano.git /tmp/pip-req-build-kuz_8k0r\n",
            "Building wheels for collected packages: Theano\n",
            "  Building wheel for Theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano: filename=Theano-1.0.5+1.geb6a4125c-cp36-none-any.whl size=2668281 sha256=b228606517b019a59f869fb2c7aee39863437840a7267c5c4f4ab44deaf534d9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gu8l3dr2/wheels/ae/32/7c/62beb8371953eb20c271b3bac7d0e56e1a2020d46994346b52\n",
            "Successfully built Theano\n",
            "Installing collected packages: Theano\n",
            "  Found existing installation: Theano 1.0.5\n",
            "    Uninstalling Theano-1.0.5:\n",
            "      Successfully uninstalled Theano-1.0.5\n",
            "Successfully installed Theano-1.0.5+1.geb6a4125c\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUyj_SatZdVN"
      },
      "source": [
        "## Importar conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VLHVlPfZkv_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/cccg8105/deeplearning-az/master/datasets/Part%201%20-%20Artificial%20Neural%20Networks%20(ANN)/Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:13].values\n",
        "y = dataset.iloc[:, 13].values"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3jrBmgeaak7"
      },
      "source": [
        "## Preprocesado de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSWC-WB3bP5u"
      },
      "source": [
        "### Conversión de datos categóricos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ViXj0Prad_w"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
        "onehotencoder = ColumnTransformer(\n",
        "    [('one_hot_encoder', OneHotEncoder(categories='auto'), [1])],   \n",
        "    remainder='passthrough'                        \n",
        ")\n",
        "X = onehotencoder.fit_transform(X)\n",
        "X = X[:, 1:]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajbXl7mMbCOs"
      },
      "source": [
        "### Dividir en entrenamiento y prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcabzICsbIV9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSA5sMkYbZ_1"
      },
      "source": [
        "### Escalado de variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLtGEsagbeve"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAltaDvAb2K1"
      },
      "source": [
        "## Construcción"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znIlucgub533"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "# Añadir las capas de entrada y primera capa oculta\n",
        "nodosIniciales = 6 # se recomienda poner la media entre los nodos de entrada y salida (11+1)/2\n",
        "inicializadorKernel = \"uniform\" # glorot_uniform|||\n",
        "funcionActivacion = \"relu\" # funcion escalon|funcion sigmoide(sigmoid)|tangente hiperbolica(tanh)| rectificador lineal(relu)\n",
        "nodosEntrada = 11 # numero de variables en la matriz de caracteristicas\n",
        "\n",
        "classifier.add(Dense(units = nodosIniciales, kernel_initializer = inicializadorKernel,  \n",
        "                     activation = funcionActivacion, input_dim = nodosEntrada))\n",
        "\n",
        "# Añadir la segunda capa oculta\n",
        "nodosCapa2 = 6\n",
        "inicializadorKernel2 = \"uniform\" \n",
        "funcionActivacion2 = \"relu\" \n",
        "classifier.add(Dense(units = nodosCapa2, kernel_initializer = inicializadorKernel2,  activation = funcionActivacion2))\n",
        "\n",
        "# Añadir la capa de salida\n",
        "nodoSalida = 1\n",
        "salidaKernel = \"uniform\" \n",
        "funcionActivacionSalida = \"sigmoid\" \n",
        "classifier.add(Dense(units = nodoSalida, kernel_initializer = salidaKernel,  activation = funcionActivacionSalida))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf85QdCniM2d"
      },
      "source": [
        "## Compilación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j_tB0XGiL6f"
      },
      "source": [
        "optimizador = \"adam\" # |||\n",
        "funcionPerdida =  \"binary_crossentropy\" # softmax|||\n",
        "metricas = [\"accuracy\"] # |||\n",
        "classifier.compile(optimizer = optimizador, loss = funcionPerdida, metrics = metricas)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WadAY9tjc5R"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZHYKPw7nIV5",
        "outputId": "146738ed-40d9-4c7a-9a87-09c7fc1714ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tamanioLote = 10\n",
        "epocas = 100\n",
        "classifier.fit(X_train, y_train,  batch_size = tamanioLote, epochs = epocas)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "800/800 [==============================] - 1s 873us/step - loss: 0.4860 - accuracy: 0.7991\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 1s 883us/step - loss: 0.4093 - accuracy: 0.8236\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 1s 862us/step - loss: 0.3948 - accuracy: 0.8275\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 1s 881us/step - loss: 0.3842 - accuracy: 0.8285\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 1s 844us/step - loss: 0.3771 - accuracy: 0.8322\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 1s 857us/step - loss: 0.3714 - accuracy: 0.8436\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 1s 861us/step - loss: 0.3681 - accuracy: 0.8466\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 1s 873us/step - loss: 0.3652 - accuracy: 0.8493\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 1s 844us/step - loss: 0.3616 - accuracy: 0.8491\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 1s 875us/step - loss: 0.3607 - accuracy: 0.8519\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 1s 880us/step - loss: 0.3586 - accuracy: 0.8533\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 1s 864us/step - loss: 0.3585 - accuracy: 0.8536\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 1s 869us/step - loss: 0.3564 - accuracy: 0.8530\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 1s 888us/step - loss: 0.3553 - accuracy: 0.8529\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 1s 863us/step - loss: 0.3546 - accuracy: 0.8534\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 1s 912us/step - loss: 0.3548 - accuracy: 0.8558\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 1s 868us/step - loss: 0.3531 - accuracy: 0.8562\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 1s 864us/step - loss: 0.3519 - accuracy: 0.8574\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 1s 926us/step - loss: 0.3522 - accuracy: 0.8558\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 1s 893us/step - loss: 0.3515 - accuracy: 0.8554\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 1s 894us/step - loss: 0.3501 - accuracy: 0.8571\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 1s 862us/step - loss: 0.3496 - accuracy: 0.8579\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 1s 872us/step - loss: 0.3494 - accuracy: 0.8568\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 1s 870us/step - loss: 0.3498 - accuracy: 0.8580\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 1s 851us/step - loss: 0.3494 - accuracy: 0.8562\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 1s 917us/step - loss: 0.3485 - accuracy: 0.8561\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 1s 879us/step - loss: 0.3478 - accuracy: 0.8596\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 1s 902us/step - loss: 0.3481 - accuracy: 0.8576\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 1s 853us/step - loss: 0.3462 - accuracy: 0.8585\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 1s 903us/step - loss: 0.3476 - accuracy: 0.8589\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 1s 847us/step - loss: 0.3473 - accuracy: 0.8570\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 1s 854us/step - loss: 0.3466 - accuracy: 0.8589\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 1s 872us/step - loss: 0.3462 - accuracy: 0.8589\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 1s 866us/step - loss: 0.3454 - accuracy: 0.8579\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 1s 863us/step - loss: 0.3443 - accuracy: 0.8575\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 1s 880us/step - loss: 0.3437 - accuracy: 0.8570\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 1s 880us/step - loss: 0.3430 - accuracy: 0.8595\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 1s 912us/step - loss: 0.3434 - accuracy: 0.8590\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 1s 867us/step - loss: 0.3418 - accuracy: 0.8596\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 1s 866us/step - loss: 0.3418 - accuracy: 0.8572\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 1s 880us/step - loss: 0.3413 - accuracy: 0.8590\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 1s 855us/step - loss: 0.3397 - accuracy: 0.8591\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 1s 860us/step - loss: 0.3405 - accuracy: 0.8608\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 1s 869us/step - loss: 0.3386 - accuracy: 0.8615\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 1s 894us/step - loss: 0.3402 - accuracy: 0.8605\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 1s 936us/step - loss: 0.3396 - accuracy: 0.8605\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 1s 897us/step - loss: 0.3393 - accuracy: 0.8600\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 1s 879us/step - loss: 0.3396 - accuracy: 0.8593\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 1s 864us/step - loss: 0.3387 - accuracy: 0.8629\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 1s 870us/step - loss: 0.3389 - accuracy: 0.8599\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 1s 880us/step - loss: 0.3379 - accuracy: 0.8601\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 1s 854us/step - loss: 0.3395 - accuracy: 0.8587\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 1s 870us/step - loss: 0.3383 - accuracy: 0.8596\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 1s 858us/step - loss: 0.3392 - accuracy: 0.8594\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 1s 890us/step - loss: 0.3386 - accuracy: 0.8579\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 1s 890us/step - loss: 0.3398 - accuracy: 0.8585\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 1s 868us/step - loss: 0.3378 - accuracy: 0.8608\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 1s 867us/step - loss: 0.3380 - accuracy: 0.8606\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 1s 934us/step - loss: 0.3384 - accuracy: 0.8599\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 1s 930us/step - loss: 0.3388 - accuracy: 0.8595\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 1s 858us/step - loss: 0.3382 - accuracy: 0.8612\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 1s 851us/step - loss: 0.3375 - accuracy: 0.8584\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 1s 890us/step - loss: 0.3375 - accuracy: 0.8615\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 1s 885us/step - loss: 0.3374 - accuracy: 0.8614\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 1s 863us/step - loss: 0.3378 - accuracy: 0.8614\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 1s 860us/step - loss: 0.3372 - accuracy: 0.8605\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 1s 890us/step - loss: 0.3382 - accuracy: 0.8610\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 1s 867us/step - loss: 0.3375 - accuracy: 0.8612\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 1s 895us/step - loss: 0.3374 - accuracy: 0.8609\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 1s 900us/step - loss: 0.3367 - accuracy: 0.8604\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 1s 864us/step - loss: 0.3369 - accuracy: 0.8606\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 1s 847us/step - loss: 0.3374 - accuracy: 0.8595\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 1s 897us/step - loss: 0.3378 - accuracy: 0.8597\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 1s 906us/step - loss: 0.3380 - accuracy: 0.8594\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 1s 876us/step - loss: 0.3370 - accuracy: 0.8629\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 1s 891us/step - loss: 0.3362 - accuracy: 0.8606\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 1s 908us/step - loss: 0.3373 - accuracy: 0.8614\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 1s 843us/step - loss: 0.3363 - accuracy: 0.8606\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 1s 916us/step - loss: 0.3366 - accuracy: 0.8621\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 1s 852us/step - loss: 0.3380 - accuracy: 0.8597\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 1s 936us/step - loss: 0.3383 - accuracy: 0.8608\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 1s 900us/step - loss: 0.3370 - accuracy: 0.8608\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 1s 910us/step - loss: 0.3384 - accuracy: 0.8586\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 1s 865us/step - loss: 0.3372 - accuracy: 0.8601\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 1s 914us/step - loss: 0.3366 - accuracy: 0.8602\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 1s 861us/step - loss: 0.3373 - accuracy: 0.8605\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 1s 923us/step - loss: 0.3364 - accuracy: 0.8624\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 1s 918us/step - loss: 0.3361 - accuracy: 0.8615\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 1s 881us/step - loss: 0.3370 - accuracy: 0.8606\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 1s 881us/step - loss: 0.3371 - accuracy: 0.8616\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 1s 882us/step - loss: 0.3372 - accuracy: 0.8602\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 1s 870us/step - loss: 0.3369 - accuracy: 0.8591\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 1s 887us/step - loss: 0.3361 - accuracy: 0.8590\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 1s 896us/step - loss: 0.3363 - accuracy: 0.8611\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 1s 863us/step - loss: 0.3365 - accuracy: 0.8601\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 1s 940us/step - loss: 0.3372 - accuracy: 0.8593\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 1s 878us/step - loss: 0.3366 - accuracy: 0.8611\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 1s 879us/step - loss: 0.3371 - accuracy: 0.8604\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 1s 856us/step - loss: 0.3364 - accuracy: 0.8601\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 1s 871us/step - loss: 0.3365 - accuracy: 0.8594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f254a467668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBbTsCyDpX6z"
      },
      "source": [
        "## Evaluar modelo con datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdkDPaMZpbjw",
        "outputId": "a5b0d3b4-4ade-423d-df51-812afc75c91a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred  = classifier.predict(X_test)\n",
        "y_pred = (y_pred>0.5)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1539,   56],\n",
              "       [ 222,  183]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK86CodXwZyx"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfl28FdEqM7c"
      },
      "source": [
        "## Mejorar y ajustar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFIkbex1swbG"
      },
      "source": [
        "### Evaluación K-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEcw09IUqPpt",
        "outputId": "f370363e-0fc7-4bc3-9d81-08b6f625248b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def build_classifier():\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Dense(units = nodosIniciales, kernel_initializer = inicializadorKernel, activation = funcionActivacion, input_dim = nodosEntrada))\n",
        "  classifier.add(Dense(units = nodosCapa2, kernel_initializer = inicializadorKernel2, activation = funcionActivacion2))\n",
        "  classifier.add(Dense(units = nodoSalida, kernel_initializer = salidaKernel, activation = funcionActivacionSalida))\n",
        "  classifier.compile(optimizer = optimizador, loss = funcionPerdida, metrics = metricas)\n",
        "  return classifier\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier, batch_size = tamanioLote, nb_epoch = epocas)\n",
        "\n",
        "tamanioBloqueEntrenamiento = 10\n",
        "tareasSimultaneas = -1 # usa todas las cpus de la pc\n",
        "mostrarDatosIntermedios = 1\n",
        "accuracies = cross_val_score(estimator=classifier, X = X_train, y = y_train, cv = tamanioBloqueEntrenamiento, \n",
        "                             n_jobs= tareasSimultaneas, verbose = mostrarDatosIntermedios)\n",
        "\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()\n",
        "\n",
        "print(mean)\n",
        "print(variance)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7985000073909759\n",
            "0.009532839676923333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.2s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGMPdJYgxVuS"
      },
      "source": [
        "- Alto sesgo, baja varianza:\n",
        "- Alto sesgo, alta varianza:\n",
        "- Bajo sesgo, baja varianza: tiene buena precision y poca varianza. Esto es lo mejor\n",
        "- Bajo sesgo, alta varianza: buena precision pero mucha varianza. Es ideal disminuir la varianza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bTNevPVs11u"
      },
      "source": [
        "### Ajuste "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdnWMoSqs38L",
        "outputId": "b2204777-60ff-4f7c-cfc2-76df61e27091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def build_classifier(optimizer):\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Dense(units = nodosIniciales, kernel_initializer = inicializadorKernel,  activation = funcionActivacion, input_dim = nodosEntrada))\n",
        "  classifier.add(Dense(units = nodosCapa2, kernel_initializer = inicializadorKernel2,  activation = funcionActivacion2))\n",
        "  classifier.add(Dense(units = nodoSalida, kernel_initializer = salidaKernel,  activation = funcionActivacionSalida))\n",
        "  classifier.compile(optimizer = optimizer, loss = funcionPerdida, metrics = metricas)\n",
        "  return classifier\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "\n",
        "rangoLotes = [25,32]\n",
        "rangoEpocas = [100, 500]\n",
        "optimizadores = ['adam', 'rmsprop']\n",
        "parameters = {\n",
        "    'batch_size' : rangoLotes,\n",
        "    'nb_epoch' : rangoEpocas, \n",
        "    'optimizer' : optimizadores\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator = classifier, \n",
        "                           param_grid = parameters, \n",
        "                           scoring = 'accuracy', \n",
        "                           cv = 10)\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_parameters = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "288/288 [==============================] - 0s 963us/step - loss: 0.5494 - accuracy: 0.7968\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "288/288 [==============================] - 0s 910us/step - loss: 0.5703 - accuracy: 0.7960\n",
            "288/288 [==============================] - 0s 898us/step - loss: 0.5432 - accuracy: 0.7956\n",
            "288/288 [==============================] - 0s 882us/step - loss: 0.5798 - accuracy: 0.7950\n",
            "288/288 [==============================] - 0s 897us/step - loss: 0.5437 - accuracy: 0.7937\n",
            "288/288 [==============================] - 0s 928us/step - loss: 0.5611 - accuracy: 0.7931\n",
            "288/288 [==============================] - 0s 901us/step - loss: 0.5521 - accuracy: 0.7968\n",
            "288/288 [==============================] - 0s 902us/step - loss: 0.5507 - accuracy: 0.7954\n",
            "288/288 [==============================] - 0s 915us/step - loss: 0.5551 - accuracy: 0.7950\n",
            "288/288 [==============================] - 0s 869us/step - loss: 0.5610 - accuracy: 0.7957\n",
            "288/288 [==============================] - 0s 921us/step - loss: 0.5737 - accuracy: 0.7967\n",
            "288/288 [==============================] - 0s 901us/step - loss: 0.5691 - accuracy: 0.7957\n",
            "288/288 [==============================] - 0s 970us/step - loss: 0.6099 - accuracy: 0.7940\n",
            "288/288 [==============================] - 0s 909us/step - loss: 0.5602 - accuracy: 0.7975\n",
            "288/288 [==============================] - 0s 949us/step - loss: 0.6052 - accuracy: 0.7922\n",
            "288/288 [==============================] - 0s 999us/step - loss: 0.6325 - accuracy: 0.7924\n",
            "288/288 [==============================] - 0s 945us/step - loss: 0.5823 - accuracy: 0.7962\n",
            "288/288 [==============================] - 0s 954us/step - loss: 0.5849 - accuracy: 0.7958\n",
            "288/288 [==============================] - 0s 930us/step - loss: 0.6239 - accuracy: 0.7932\n",
            "288/288 [==============================] - 0s 870us/step - loss: 0.5639 - accuracy: 0.7954\n",
            "288/288 [==============================] - 0s 921us/step - loss: 0.5471 - accuracy: 0.7969\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5475 - accuracy: 0.7965\n",
            "288/288 [==============================] - 0s 892us/step - loss: 0.5943 - accuracy: 0.7947\n",
            "288/288 [==============================] - 0s 868us/step - loss: 0.5657 - accuracy: 0.7968\n",
            "288/288 [==============================] - 0s 936us/step - loss: 0.5523 - accuracy: 0.7937\n",
            "288/288 [==============================] - 0s 946us/step - loss: 0.5550 - accuracy: 0.7939\n",
            "288/288 [==============================] - 0s 916us/step - loss: 0.5643 - accuracy: 0.7947\n",
            "288/288 [==============================] - 0s 919us/step - loss: 0.5799 - accuracy: 0.7956\n",
            "288/288 [==============================] - 0s 912us/step - loss: 0.5541 - accuracy: 0.7956\n",
            "288/288 [==============================] - 0s 887us/step - loss: 0.5748 - accuracy: 0.7956\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.7956\n",
            "288/288 [==============================] - 0s 929us/step - loss: 0.5834 - accuracy: 0.7962\n",
            "288/288 [==============================] - 0s 883us/step - loss: 0.5996 - accuracy: 0.7939\n",
            "288/288 [==============================] - 0s 922us/step - loss: 0.6022 - accuracy: 0.7968\n",
            "288/288 [==============================] - 0s 957us/step - loss: 0.6124 - accuracy: 0.7919\n",
            "288/288 [==============================] - 0s 1ms/step - loss: 0.5881 - accuracy: 0.7939\n",
            "288/288 [==============================] - 0s 949us/step - loss: 0.5626 - accuracy: 0.7969\n",
            "288/288 [==============================] - 0s 1000us/step - loss: 0.5771 - accuracy: 0.7947\n",
            "288/288 [==============================] - 0s 932us/step - loss: 0.5606 - accuracy: 0.7947\n",
            "288/288 [==============================] - 0s 917us/step - loss: 0.5703 - accuracy: 0.7951\n",
            "225/225 [==============================] - 0s 880us/step - loss: 0.5938 - accuracy: 0.7942\n",
            "225/225 [==============================] - 0s 929us/step - loss: 0.5966 - accuracy: 0.7946\n",
            "225/225 [==============================] - 0s 918us/step - loss: 0.5922 - accuracy: 0.7940\n",
            "225/225 [==============================] - 0s 902us/step - loss: 0.5705 - accuracy: 0.7975\n",
            "225/225 [==============================] - 0s 908us/step - loss: 0.6039 - accuracy: 0.7903\n",
            "225/225 [==============================] - 0s 885us/step - loss: 0.5961 - accuracy: 0.7911\n",
            "225/225 [==============================] - 0s 906us/step - loss: 0.5732 - accuracy: 0.7969\n",
            "225/225 [==============================] - 0s 919us/step - loss: 0.6069 - accuracy: 0.7935\n",
            "225/225 [==============================] - 0s 937us/step - loss: 0.5959 - accuracy: 0.7935\n",
            "225/225 [==============================] - 0s 944us/step - loss: 0.5931 - accuracy: 0.7939\n",
            "225/225 [==============================] - 0s 935us/step - loss: 0.5943 - accuracy: 0.7965\n",
            "225/225 [==============================] - 0s 979us/step - loss: 0.6098 - accuracy: 0.7953\n",
            "225/225 [==============================] - 0s 937us/step - loss: 0.6294 - accuracy: 0.7932\n",
            "225/225 [==============================] - 0s 947us/step - loss: 0.6140 - accuracy: 0.7960\n",
            "225/225 [==============================] - 0s 894us/step - loss: 0.5803 - accuracy: 0.7937\n",
            "225/225 [==============================] - 0s 953us/step - loss: 0.5976 - accuracy: 0.7931\n",
            "225/225 [==============================] - 0s 930us/step - loss: 0.6123 - accuracy: 0.7954\n",
            "225/225 [==============================] - 0s 937us/step - loss: 0.5996 - accuracy: 0.7939\n",
            "225/225 [==============================] - 0s 958us/step - loss: 0.5834 - accuracy: 0.7954\n",
            "225/225 [==============================] - 0s 952us/step - loss: 0.6258 - accuracy: 0.7936\n",
            "225/225 [==============================] - 0s 978us/step - loss: 0.6018 - accuracy: 0.7949\n",
            "225/225 [==============================] - 0s 942us/step - loss: 0.5973 - accuracy: 0.7951\n",
            "225/225 [==============================] - 0s 946us/step - loss: 0.5893 - accuracy: 0.7956\n",
            "225/225 [==============================] - 0s 932us/step - loss: 0.5714 - accuracy: 0.7975\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5947 - accuracy: 0.7931\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.7936\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.7949\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5857 - accuracy: 0.7958\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5949 - accuracy: 0.7940\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5871 - accuracy: 0.7961\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.5948 - accuracy: 0.7967\n",
            "225/225 [==============================] - 0s 975us/step - loss: 0.6095 - accuracy: 0.7960\n",
            "225/225 [==============================] - 0s 962us/step - loss: 0.6262 - accuracy: 0.7946\n",
            "225/225 [==============================] - 0s 960us/step - loss: 0.5892 - accuracy: 0.7972\n",
            "225/225 [==============================] - 0s 927us/step - loss: 0.6191 - accuracy: 0.7911\n",
            "225/225 [==============================] - 0s 954us/step - loss: 0.6172 - accuracy: 0.7936\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.7951\n",
            "225/225 [==============================] - 0s 1ms/step - loss: 0.6202 - accuracy: 0.7939\n",
            "225/225 [==============================] - 0s 943us/step - loss: 0.6117 - accuracy: 0.7936\n",
            "225/225 [==============================] - 0s 939us/step - loss: 0.5949 - accuracy: 0.7956\n",
            "320/320 [==============================] - 0s 947us/step - loss: 0.5325 - accuracy: 0.7960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lURNzjkSb1Ce",
        "outputId": "060a2439-2a09-4b06-cc66-47807097b8af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(best_parameters)\n",
        "print(best_accuracy)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 25, 'nb_epoch': 100, 'optimizer': 'adam'}\n",
            "0.796\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}